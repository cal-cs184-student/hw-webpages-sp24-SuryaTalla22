<html>
	<head>
		<title>CS184 Assignment 1 - Surya Tallavarjula</title>
	</head>
	<body>
		<h1>Overview</h1>
		<p>In this Assignment, we cover rasterizing images. In order to do this, we break up the image into triangles, and feed groups of 3 points into the rasterization pipeline. Depending on the desired image, there may or may not be some texture that needs to be mapped to the screen space: if so, there is an associated mapping to from pixel space to texture space. In any case, raw point sampling generally leads to jagged edges and aliasing: our pixel space just isn't high resolution enough to capture all of this detail. There are a number of techniques we can use to combat this. Firstly, we can supersample by taking multiple samples within the region of one pixel, and then taking the average of the values. This is very effective the more samples you have per pixel, but can be very costly. For texture mapping, there are much more efficient ways to implement anti-aliasing. We can implement bilinear interpolation to sample pixel locations in the texture space instead of just returning the color of the nearest pixel. Furthermore, we can utilize a mip-map with decreasing resolutions of the texture: when the step size in texture space is relatively small for a step in the rendering space, we opt for a higher resolution image. When step size in texture space is relatively large, we opt for a lower resolution image to combat potential aliasing. This is a low-cost, effective way to minimize aliasing in texture mapping. Ultimately, we will explore the fundamentals of image rasterization and texture mapping, as well as techniques to reduce aliasing while maintaining efficiency.</p>
		<h2>Task 1: Drawing Single Color Triangles</h2>
		<p>For the drawing triangles program, we are given three points. Our task is to figure out which pixels fall within those three points and fill them in with the proper color. There is a very clever way to do so, utilizing vector algebra. Essentially, for each of the bounding lines, we can perform a 90 degrees counter-clockwise rotation to get the vector normal. Then, taking a dot product with this vector encodes a cosine operation (a &#8901; b = |a||b|cos(x)), which is positive over (-&#960;/2, &#960;/2), zero for +/-&#960;/2, and negative for (&#960;/2, 3&#960;/2). This tells us everything we need to know about which side of a line a point is on, and if we do this for all three lines of a triangle we can tell whether or not the point is within the triangle. We execute this as follows: the dot operation for a vector denoted by points (x1, y1) and (x2, y2) is simply (x - x1, y - y1) &#8901; (-(y2 - y1), (x2 - x1)). We perform this operation three times in a row from point A to B, then B to C, then C to A. What we are left with is: </p>
		<img src="triangle_diagram184-1.png" alt="A diagram of the possible normal vectors of a triangle denoted by point A, B, and C" width="800" height="450">
		<p>In this diagram, we show that there are two possibilities: all normal vectors could be pointing outwards or inwards. In the outwards case we want all dot products to be negative (or zero), and for the inwards case we want all dot products to be positive (or zero). When these conditions are met, we know the point is inside or on the boundary of a triangle, and we know to fill it in. Now, we can iterative through all points within the bounding box of the triangle, evaluating wether the pixels are in the triangle using this method. It is worth noting that we actually sample at the +0.5 position, meaning point (3, 4) actually corresponds visually to (3.5, 4.5). Essentially, my algorithm is as follows: first, in the rasterize triangle function, I find the minimum and the maximum bounds for the x and y coordinates. Since there are three points, I accomplish this using a chain of min or max such as min(min(A, B), min(B, C)). Then, I set these parameters as the bounds for the for loop. For each point within this 'box', I add an offset of 0.5 to each coordinate and test whether it is in the triangle, outsourcing this process to a helper function which does the dot product procedure as described and returns true if all points are <= 0 or >= 0 and false otherwise. If the point is in the triangle, I call fill pixel on the x and y coordinates with the color provided. Here are the results of the algorithm on a sample svg file: </p>
		<img src="Screenshot 2024-02-09 034133.png" alt="results of the triangle drawing algorithm" width="800" height="450">
		<h2>Task 2: Antialiasing By Supersampling</h2>
		<p>The essential theory behind supersampling is that we average some number of values per pixel for every pixel on the screen. At a theoretical level, this is an approximation of a convolution, which is the exact average within a given bound for every value. A convolution in theory filters out all high frequencies, stopping all aliasing when filtering at the nyquist frequency. If we supersample some finite number of points within a pixel space, we can approximate this convolution process. <br>Essentially, my algorithm is as follows: first, I add two nested loops to the existing rasterize triangle with dimension of sqrt(sample_rate). This will iterate through all the values in the pixel, the number of which is specified by the sampling rate. Then, I compute whether the points are inside the triangle in the same manner as before, accounting for a relative offset of 0.5 for each point to capture the value directly in the center of the pixel. The Color value is then recorded in the sample buffer, which store the values with dimension width*height*sample_rate. We get the respective index by considering this to be a width*sqrt(sample rate) by height*sqrt(sample rate) array, and indexing in the same way as before. Now, we don't call 'fill pixel': instead, we manipulate the sample buffer directly and proceed to the next function 'resolve to framebuffer'. Here, we loop through every pixel, and add nested loops for the sample values in each pixel. We keep track of all the RGB values for each color, and then average them at the end. Then, these RGB values get passed into the frame buffer target array, which stores the raw RGB values that actually get drawn to the screen. With this, our supersampling procedure is complete, but we still need to modify our fill pixel function to account for an augmented sample buffer: all values that correspond to a given pixel value must be filled instead of just one sample value. The results of supersampling the same image with different sample rates using this algorithm are shown below. </p>
		<img src="images/Screenshot 2024-02-09 121423.png" alt="sample rate 1" width="800" height="430">
		<img src="images/Screenshot 2024-02-09 121458.png" alt="sample rate 1" width="800" height="430">
		<img src="images/Screenshot 2024-02-09 121529.png" alt="sample rate 1" width="800" height="430">
		<img src="images/Screenshot 2024-02-09 121610.png" alt="sample rate 1" width="800" height="430">
		<p>As observed, the images become proggressively less jagged-edged and visually smoothers, especially for sharp angles. At the pixel level, one can observe what is really happening: As the sample rate goes up, we obtain a better approximation of the average of all samples within the given pixel, providing a more nuanced rendering.</p>
		<h2>Task 3: Transforms</h2>
		<p></p>
		<h2>Task 4: Barycentric Coordinates</h2>
		<p></p>
		<h2>Task 5: Pixel Sampling For Texture Mapping</h2>
		<p></p>
		<h2>Task 6: Level Sampling With Mip-Maps For Texture Mapping</h2>
		<p></p>
	
	</body>
</html>
